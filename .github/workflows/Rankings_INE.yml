name: DGT · Rankings INE (Parquet → CSV en Drive)

on:
  workflow_dispatch:
    inputs:
      location:
        description: "ine=XXXXX | mun=Nombre;provincia=...;ccaa=..."
        required: false
      period:
        description: "anio=YYYY | start=yyyymm;end=yyyymm"
        required: false
      filters:
        description: "marca=...;modelo=...;combustible=..."
        required: false
      options:
        description: "by_combustible=true;mix=true;vs_prev=false;timeseries=false"
        required: false
        default: "by_combustible=false;mix=true;vs_prev=false;timeseries=false"
      top:
        description: "Top N"
        required: false
        default: "20"
      format:
        description: "table|csv"
        required: false
        default: "table"
      chunksize:
        description: "Solo si el input fuera CSV"
        required: false
      dry_run:
        description: "true|false (no sube ficheros si true)"
        required: false
        default: "false"

concurrency:
  group: dgt-rankings
  cancel-in-progress: false

env:
  GOOGLE_OAUTH_B64: ${{ secrets.GOOGLE_OAUTH_B64 }}
  GOOGLE_DRIVE_SCOPE: https://www.googleapis.com/auth/drive.file
  BCA_MONTHLY_FOLDER_ID: ${{ secrets.BCA_MONTHLY_FOLDER_ID }}
  DGT_ANALISIS_FOLDER_ID: ${{ secrets.DGT_ANALISIS_FOLDER_ID }}

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          pip install pyarrow pandas google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2

      - name: Prepare workspace
        run: |
          mkdir -p data
          mkdir -p outputs

      # ↓↓↓ Descarga cloud (estilo BCA) ↓↓↓
      - name: Fetch latest Parquet from BCA monthly folder
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python - << 'PY'
          from pathlib import Path
          from gdrive_auth import authenticate_drive
          from googleapiclient.http import MediaIoBaseDownload
          import io, os
          FOLDER_ID = os.environ["BCA_MONTHLY_FOLDER_ID"]
          svc = authenticate_drive()
          q = " and ".join([
            f"'{FOLDER_ID}' in parents",
            "trashed = false"
          ])
          resp = svc.files().list(
            q=q, fields="files(id,name,modifiedTime,mimeType)",
            orderBy="modifiedTime desc",
            pageSize=1000, includeItemsFromAllDrives=True, supportsAllDrives=True
          ).execute()
          files = resp.get("files", [])
          target = None
          for f in files:
            if f["name"].lower().endswith(".parquet") and "agg_transmisiones_ine" in f["name"].lower():
              target = f; break
          if target is None:
            for f in files:
              if f["name"].lower().endswith(".parquet"):
                target = f; break
          if target is None:
            raise SystemExit("⛔ No hay .parquet en la carpeta BCA_MONTHLY_FOLDER_ID.")
          fid, name = target["id"], target["name"]
          print("Seleccionado:", name)
          req = svc.files().get_media(fileId=fid)
          buf = io.BytesIO()
          dl = MediaIoBaseDownload(buf, req)
          done = False
          while not done:
              _, done = dl.next_chunk()
          Path(name).write_bytes(buf.getvalue())
          print(f"✅ Descargado {name}")
          PY


      - name: Build CLI flags from compact inputs
        id: flags
        shell: bash
        run: |
          set -euo pipefail
          FLAGS=""

          parse_kv() {
            local s="$1"
            echo "$s" | tr ';' '\n' | sed '/^[[:space:]]*$/d' | while IFS='=' read -r k v; do
              k="$(echo "$k" | xargs)"; v="$(echo "$v" | xargs)"
              [[ -z "${k:-}" || -z "${v:-}" ]] && continue
              case "$k" in
                ine) FLAGS+=" --ine $v" ;;
                mun) FLAGS+=" --mun \"$v\"" ;;
                provincia) FLAGS+=" --provincia \"$v\"" ;;
                ccaa) FLAGS+=" --ccaa \"$v\"" ;;
                anio) FLAGS+=" --anio $v" ;;
                start) FLAGS+=" --start $v" ;;
                end) FLAGS+=" --end $v" ;;
                marca) FLAGS+=" --marca \"$v\"" ;;
                modelo) FLAGS+=" --modelo \"$v\"" ;;
                combustible) FLAGS+=" --combustible \"$v\"" ;;
                by_combustible) [[ "$v" == "true" ]] && FLAGS+=" --by-combustible" ;;
                mix|mix_combustible) [[ "$v" == "true" ]] && FLAGS+=" --mix-combustible" ;;
                vs_prev) [[ "$v" == "true" ]] && FLAGS+=" --vs-prev" ;;
                timeseries) [[ "$v" == "true" ]] && FLAGS+=" --timeseries" ;;
                chunksize) [[ -n "$v" ]] && FLAGS+=" --chunksize $v" ;;
              esac
            done
          }

          # location / period / filters / options
          [[ -n "${{ github.event.inputs.location }}" ]] && parse_kv "${{ github.event.inputs.location }}"
          [[ -n "${{ github.event.inputs.period }}" ]] && parse_kv "${{ github.event.inputs.period }}"
          [[ -n "${{ github.event.inputs.filters }}" ]] && parse_kv "${{ github.event.inputs.filters }}"
          [[ -n "${{ github.event.inputs.options }}" ]] && parse_kv "${{ github.event.inputs.options }}"
          [[ -n "${{ github.event.inputs.format }}" ]] && FLAGS+=" --format ${{ github.event.inputs.format }}"
          [[ -n "${{ github.event.inputs.chunksize }}" ]] && parse_kv "chunksize=${{ github.event.inputs.chunksize }}"
          [[ "${{ github.event.inputs.dry_run }}" == "true" ]] && FLAGS+=" --dry-run"

          # top
          FLAGS+=" --top ${{ github.event.inputs.top }}"

          {
            echo 'flags<<EOF'
            echo "$FLAGS"
            echo 'EOF'
          } >> "$GITHUB_OUTPUT"

          echo "FLAGS: $FLAGS"

      - name: Run rankings_ine.py (Parquet input)
        env:
          MUNICIPIOS_INE_CSV: municipios_ine.csv
        run: |
          INP="$(ls -1 *.parquet | head -n1)"
          echo "Usando Parquet: $INP"
          python rankings_ine.py ${{ steps.flags.outputs.flags }} --data "$INP" --show

      - name: Upload outputs to Drive (DGT_ANALISIS_FOLDER_ID)
        if: ${{ github.event.inputs.dry_run != 'true' }}
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python - << 'PY'
          from pathlib import Path
          from gdrive_auth import authenticate_drive
          from googleapiclient.http import MediaFileUpload
          import os, sys
          FOLDER_ID = os.environ["DGT_ANALISIS_FOLDER_ID"]
          svc = authenticate_drive()
          files = list(Path(".").glob("ranking_*.csv")) + \
                  list(Path(".").glob("ranking_*.json")) + \
                  list(Path(".").glob("mix_combustible_*.csv")) + \
                  list(Path(".").glob("mix_combustible_*.json")) + \
                  list(Path(".").glob("timeseries_*.csv")) + \
                  list(Path(".").glob("timeseries_*.json"))
          if not files:
            print("⚠️ No hay ficheros para subir."); sys.exit(0)
          for p in files:
            media = MediaFileUpload(str(p), resumable=True)
            body = {"name": p.name, "parents": [FOLDER_ID]}
            svc.files().create(body=body, media_body=media, supportsAllDrives=True).execute()
            print("⬆️  Uploaded:", p.name)
          print("✅ Subida completada.")
          PY

      - name: Upload artifact (backup)
        uses: actions/upload-artifact@v4
        with:
          name: dgt-rankings
          path: |
            ranking_*.csv
            ranking_*.json
            mix_combustible_*.csv
            mix_combustible_*.json
            timeseries_*.csv
            timeseries_*.json

